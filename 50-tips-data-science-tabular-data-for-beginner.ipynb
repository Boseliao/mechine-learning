{"cells":[{"metadata":{"papermill":{"duration":0.030237,"end_time":"2020-11-15T02:05:17.81389","exception":false,"start_time":"2020-11-15T02:05:17.783653","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# 50 Tips for Data Science for tabular data for beginners (in progress...)\n## Frequently used useful code for:\n* Import libraries\n* Data download\n* Data cleaning\n* FE\n* Modeling\n* Analysing, and visualization of modeling results\n* Prediction and submitting of modeling results\netc.\n\n### With BONUS - the short solution for Competition [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) with LB=0.80382 (Top 4%)\n\n### Part of tips from the first versions of the notebook see in a new notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)\n\nLater I will publish another notebook for EDA."},{"metadata":{},"cell_type":"markdown","source":"## It's done 45 tips: 1.1-1.5, 2.1-2.7, 3.1, 3.2, 4.1-4.8, 5.1-5.5, 6.1-6.16, 7.2, 8"},{"metadata":{"papermill":{"duration":0.028785,"end_time":"2020-11-15T02:05:18.049591","exception":false,"start_time":"2020-11-15T02:05:18.020806","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Acknowledgements\n\n### Datasets:\n* for Classification task solutions - competition's dataset [Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic)\n* for Classification task solutions - [Heart Disease UCI](https://www.kaggle.com/ronitf/heart-disease-uci)\n* for Regression task solutions - my dataset [Ammonium prediction in river water](https://www.kaggle.com/vbmokin/ammonium-prediction-in-river-water)\n* from API for Regression task solutions - official data of COVID-19 in Ukraine (https://covid19.rnbo.gov.ua/)\n* for NLP task - [NLP : Reports & News Classification](https://www.kaggle.com/vbmokin/nlp-reports-news-classification)\n\n### Notebooks:\n* [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)\n* [Data Science for tabular data: Advanced Techniques](https://www.kaggle.com/vbmokin/data-science-for-tabular-data-advanced-techniques)\n* [EDA for tabular data: Advanced Techniques](https://www.kaggle.com/vbmokin/eda-for-tabular-data-advanced-techniques)\n* [Heart Disease - Automatic AdvEDA & FE & 20 models](https://www.kaggle.com/vbmokin/heart-disease-automatic-adveda-fe-20-models)\n* [COVID in UA: Prophet with 4, Nd seasonality](https://www.kaggle.com/vbmokin/covid-in-ua-prophet-with-4-nd-seasonality)\n* [Top score : one line of the prediction](https://www.kaggle.com/vbmokin/titanic-top-score-one-line-of-the-prediction)\n* [AI-ML-DS Training. L3AT: NH4 - NN models](https://www.kaggle.com/vbmokin/ai-ml-ds-training-l3at-nh4-nn-models)\n* https://www.dataschool.io/python-pandas-tips-and-tricks/\n* https://github.com/rougier/numpy-100"},{"metadata":{"papermill":{"duration":0.029848,"end_time":"2020-11-15T02:05:18.108536","exception":false,"start_time":"2020-11-15T02:05:18.078688","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n## Table of Contents\n\n1. [Import main libraries](#1)\n    - [Tip 1.1. Import the most popular and useful main Python libraries](#1.1)\n    - [Tip 1.2. Warnings - ignore all](#1.2)\n    - [Tip 1.3. Ignore all warnings about later execution](#1.3)    \n    - [Tip 1.4. Install new libraries or packages with the given version](#1.4)\n    - [Tip 1.5. Import module or subpackage](#1.5)\n1. [Data download](#2)\n    - [Tip 2.1. Download typical csv-file to DataFrame](#2.1)\n    - [Tip 2.2. Download csv-file saved from MS Excel-file to DataFrame](#2.2)\n    - [Tip 2.3. Download csv-file with Cyrillic text to DataFrame](#2.3)\n    - [Tip 2.4. Download csv-file with given data types and NAN values](#2.4)\n    - [Tip 2.5. Download 1% data with random rows from big csv-file](#2.5)\n    - [Tip 2.6. Internally process the file in chunks (low_memory)](#2.6)    \n    - [Tip 2.7. Download json-data via API in Kaggle](#2.7)\n    - [Tip 2.8. Selection data from DataFrame (Pandas Tips)](#2.8)\n1. [Auxiliary functions](#3)\n    - [Tip 3.1. Pandas option for output data](#3.1)\n    - [Tip 3.2. The garbage collector](#3.2)\n1. [EDA & Data cleaning](#4)\n    - [Tip 4.1. Count of rows that match a condition](#4.1)\n    - [Tip 4.2. Combine the small categories into a single category named \"Other\"](#4.2)\n    - [Tip 4.3. Count the missing values](#4.3)\n    - [Tip 4.4. Convert one type of values to others](#4.4)\n    - [Tip 4.5. Replaced inf, -inf, nan to given value](#4.5)\n    - [Tip 4.6. Filtering the missing data in DataFrame](#4.6)\n    - [Tip 4.7. Generate descriptive statistics](#4.7)    \n1. [FE](#5)\n    - [Tip 5.1. Search and encoding categorical columns](#5.1)\n    - [Tip 5.2. Difference or rolling of values in DataFrame](#5.2)\n    - [Tip 5.3. Data dropping (rows or columns removing) in DataFrame](#5.3)\n    - [Tip 5.4. Date in str format to date in datetime format in DataFrame](#5.4)\n    - [Tip 5.5. MinMaxScaling data in DataFrame](#5.5)\n1. [Modeling](#6)\n    - [Tip 6.1. Data preparation with standardization for modeling](#6.1)\n    - [Tip 6.2. Splitting data with train_test_split](#6.2)\n    - [Tip 6.3. Accuracy score for train and test prediction](#6.3)\n    - [Tip 6.4. Classification report](#6.4)\n    - [Tip 6.5. Linear Regression](#6.5)\n    - [Tip 6.6. Support Vector Machines](#6.6)\n    - [Tip 6.7. Linear SVC](#6.7)\n    - [Tip 6.8. Decision Tree Classifier & Regressor](#6.8)\n    - [Tip 6.9. Random Forest Classifier & Regressor](#6.9)\n    - [Tip 6.10. XGB Classifier](#6.10)\n    - [Tip 6.11. LGBM Classifier](#6.11)\n    - [Tip 6.12. Logistic Regression](#6.12)\n    - [Tip 6.13. k-Nearest Neighbors (KNN)](#6.13)\n    - [Tip 6.14. MLP Classifier](#6.14)\n    - [Tip 6.15. Voting Classifier](#6.15)\n    - [Tip 6.16. Feature importance diagram](#6.16)\n1. [Analysis and visualization of modeling results](#7)\n    - [Tip 7.1. Output results](#7.1)\n    - [Tip 7.2. Drawing plot data with modeling results](#7.2)\n    - [Tip 7.3. Drawing plot data of DataFrame (Pandas)](#7.3)\n1. [BONUS](#8)\n    - [Tip 8.1. Submission data from DataFrame to Kaggle competition](#8.1)"},{"metadata":{"papermill":{"duration":0.028871,"end_time":"2020-11-15T02:05:18.166715","exception":false,"start_time":"2020-11-15T02:05:18.137844","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 1. Import main libraries<a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"### Tip 1.1. Import the most popular and useful main Python libraries<a class=\"anchor\" id=\"1.1\"></a>"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-11-15T02:05:18.233841Z","iopub.status.busy":"2020-11-15T02:05:18.233052Z","iopub.status.idle":"2020-11-15T02:05:18.481486Z","shell.execute_reply":"2020-11-15T02:05:18.480672Z"},"papermill":{"duration":0.285751,"end_time":"2020-11-15T02:05:18.481628","exception":false,"start_time":"2020-11-15T02:05:18.195877","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 1.2. Warnings - ignore all<a class=\"anchor\" id=\"1.2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 1.3. Ignore all warnings about later execution <a class=\"anchor\" id=\"1.3\"></a>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 1.4. Install new libraries or packages with the given version<a class=\"anchor\" id=\"1.4\"></a>"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install pandas-profiling==2.11.0","execution_count":4,"outputs":[{"output_type":"stream","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f3adb0acb10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pandas-profiling/\u001b[0m\n^C\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 1.5. Import module or subpackage <a class=\"anchor\" id=\"1.5\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, confusion_matrix","execution_count":5,"outputs":[]},{"metadata":{"papermill":{"duration":0.028564,"end_time":"2020-11-15T02:05:18.539412","exception":false,"start_time":"2020-11-15T02:05:18.510848","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 2. Data download<a class=\"anchor\" id=\"2\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"### Tip 2.1. Download typical csv-file to DataFrame <a class=\"anchor\" id=\"2.1\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_titanic = pd.read_csv('../input/titanic/train.csv')\ndata_titanic.head(3)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_health = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")\ndata_health.tail(3)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n300   68    1   0       144   193    1        1      141      0      3.4   \n301   57    1   0       130   131    0        1      115      1      1.2   \n302   57    0   1       130   236    0        0      174      0      0.0   \n\n     slope  ca  thal  target  \n300      1   2     3       0  \n301      1   1     3       0  \n302      1   1     2       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>300</th>\n      <td>68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>1</td>\n      <td>141</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>1</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>57</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 2.2. Download csv-file saved from MS Excel-file to DataFrame <a class=\"anchor\" id=\"2.2\"></a>\nMS Excel with saves csv-files with the default settings with the delimiter \";\""},{"metadata":{"trusted":true},"cell_type":"code","source":"data_water = pd.read_csv('../input/ammonium-prediction-in-river-water/PB_1996_2019_NH4.csv', sep=';')\ndata_water.tail(3)","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"      ID_Station        Date    NH4  Distance\n3496          35  04.07.2019  0.000     797.0\n3497          35  06.08.2019  0.022     797.0\n3498          35  04.09.2019  0.159     797.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_Station</th>\n      <th>Date</th>\n      <th>NH4</th>\n      <th>Distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3496</th>\n      <td>35</td>\n      <td>04.07.2019</td>\n      <td>0.000</td>\n      <td>797.0</td>\n    </tr>\n    <tr>\n      <th>3497</th>\n      <td>35</td>\n      <td>06.08.2019</td>\n      <td>0.022</td>\n      <td>797.0</td>\n    </tr>\n    <tr>\n      <th>3498</th>\n      <td>35</td>\n      <td>04.09.2019</td>\n      <td>0.159</td>\n      <td>797.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_water['date'] = pd.to_datetime(data_water['Date'], format='%d.%m.%Y', errors='coerce').dt.to_period('m')\ndata_water = data_water[['ID_Station','date','NH4']]\ndata_water_id_list = data_water['ID_Station'].unique().tolist()\ndata_water_id_str_list = [str(x) for x in data_water_id_list]\ndata_water = pd.pivot_table(data_water, values='NH4', index=['date'], columns='ID_Station')\ndata_water = data_water[[27, 28, 29]]\ndata_water.columns = ['target', 'Kl', \"Khm\"]\ndata_water = data_water.dropna().reset_index(drop=False)\ndata_water","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"        date  target    Kl   Khm\n0    1993-02   1.400  0.06  0.06\n1    1993-11   0.625  0.75  0.61\n2    1994-02   1.550  1.25  1.08\n3    1994-03   0.550  1.50  0.87\n4    1994-04   0.410  0.43  0.45\n..       ...     ...   ...   ...\n298  2019-06   0.300  0.37  0.50\n299  2019-07   0.360  0.37  0.33\n300  2019-08   0.430  0.35  0.30\n301  2019-09   0.250  0.26  0.21\n302  2019-10   0.380  0.41  0.32\n\n[303 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>target</th>\n      <th>Kl</th>\n      <th>Khm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1993-02</td>\n      <td>1.400</td>\n      <td>0.06</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1993-11</td>\n      <td>0.625</td>\n      <td>0.75</td>\n      <td>0.61</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1994-02</td>\n      <td>1.550</td>\n      <td>1.25</td>\n      <td>1.08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1994-03</td>\n      <td>0.550</td>\n      <td>1.50</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1994-04</td>\n      <td>0.410</td>\n      <td>0.43</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>2019-06</td>\n      <td>0.300</td>\n      <td>0.37</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>2019-07</td>\n      <td>0.360</td>\n      <td>0.37</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>2019-08</td>\n      <td>0.430</td>\n      <td>0.35</td>\n      <td>0.30</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>2019-09</td>\n      <td>0.250</td>\n      <td>0.26</td>\n      <td>0.21</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>2019-10</td>\n      <td>0.380</td>\n      <td>0.41</td>\n      <td>0.32</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 2.3. Download csv-file with Cyrillic text to DataFrame <a class=\"anchor\" id=\"2.3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_nlp = pd.read_csv('../input/nlp-reports-news-classification/water_problem_nlp_ua_for_Kaggle_100.csv', delimiter=';', \n                 header=0, encoding='cp1251')\ndata_nlp.tail(3)","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"                                                 text  env_problems  \\\n97  Використання даних величин запропоноване групо...           0.0   \n98  Оцінка хімічного статусу виділених водних тіл ...           0.0   \n99  Для визначення рівнів надійності оцінки за заг...           0.0   \n\n    pollution  treatment  climate  biomonitoring  \n97        NaN        NaN      NaN            NaN  \n98        NaN        NaN      NaN            NaN  \n99        NaN        NaN      NaN            NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>env_problems</th>\n      <th>pollution</th>\n      <th>treatment</th>\n      <th>climate</th>\n      <th>biomonitoring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>97</th>\n      <td>Використання даних величин запропоноване групо...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Оцінка хімічного статусу виділених водних тіл ...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Для визначення рівнів надійності оцінки за заг...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 2.4. Download csv-file with given data types and NAN values<a class=\"anchor\" id=\"2.4\"></a>\nThe data type \"Int64\" allows the presence of NAN values during import, in contrast to the data type \"int\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/nlp-reports-news-classification/water_problem_nlp_ua_for_Kaggle_100.csv', delimiter=';', \n                 header=0, encoding='cp1251', \n                 dtype = {'text': str, \n                          'env_problems': 'Int64',\n                          'pollution': 'Int64', \n                          'treatment': 'Int64',\n                          'climate': 'Int64',\n                          'biomonitoring': 'Int64'})\ndf.head(10)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"                                                text  env_problems  pollution  \\\n0  У поверхневі води басейну Південного Бугу скид...             1          1   \n1  Згідно з державною статистичною звітністю (фор...             1          1   \n2  Показники об’ємів стічних вод серед різних гал...             1          1   \n3  Частка легкокиснюваних органічних речовин оцін...             1          1   \n4  Функціонування промисловості призводить до ски...             1          1   \n5  Із 92 міських поселень лише у 51 населеному пу...             1       <NA>   \n6  Населені пункти які не мають каналізаційної ме...             1       <NA>   \n7  Виробничі управління житлово-комунального госп...             1       <NA>   \n8  Обладнання очисних споруд вкрай зношене кількі...             1       <NA>   \n9  Нинішній стан каналізаційних мереж також викли...             1       <NA>   \n\n   treatment  climate  biomonitoring  \n0       <NA>     <NA>           <NA>  \n1       <NA>     <NA>           <NA>  \n2       <NA>     <NA>           <NA>  \n3       <NA>     <NA>           <NA>  \n4       <NA>     <NA>           <NA>  \n5       <NA>     <NA>           <NA>  \n6       <NA>     <NA>           <NA>  \n7          1     <NA>           <NA>  \n8          1     <NA>           <NA>  \n9          1     <NA>           <NA>  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>env_problems</th>\n      <th>pollution</th>\n      <th>treatment</th>\n      <th>climate</th>\n      <th>biomonitoring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>У поверхневі води басейну Південного Бугу скид...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Згідно з державною статистичною звітністю (фор...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Показники об’ємів стічних вод серед різних гал...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Частка легкокиснюваних органічних речовин оцін...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Функціонування промисловості призводить до ски...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Із 92 міських поселень лише у 51 населеному пу...</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Населені пункти які не мають каналізаційної ме...</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Виробничі управління житлово-комунального госп...</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Обладнання очисних споруд вкрай зношене кількі...</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Нинішній стан каналізаційних мереж також викли...</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 2.5. Download 1% data with random rows from big csv-file<a class=\"anchor\" id=\"2.5\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/ammonium-prediction-in-river-water/PB_1996_2019_NH4.csv', sep=';', \n                 skiprows = lambda x: x>0 and np.random.rand() > 0.01)\nprint(\"The shape of the df is {}. It has been reduced 100 times!\".format(df.shape))\n\n\n'''\nHow it works:\nskiprows accepts a function that is evaluated against the integer index.\nx > 0 makes sure that the headers is not skipped\nnp.random.rand() > 0.01 returns True 99% of the tie, thus skipping 99% of the time.\nNote that we are using skiprows\n'''\ndf.head(3)","execution_count":20,"outputs":[{"output_type":"stream","text":"The shape of the df is (32, 4). It has been reduced 100 times!\n","name":"stdout"},{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"   ID_Station        Date    NH4  Distance\n0          14  03.09.2013  0.750       0.5\n1          16  04.08.1997  0.125     153.0\n2          16  04.04.2013  0.110     153.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_Station</th>\n      <th>Date</th>\n      <th>NH4</th>\n      <th>Distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14</td>\n      <td>03.09.2013</td>\n      <td>0.750</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16</td>\n      <td>04.08.1997</td>\n      <td>0.125</td>\n      <td>153.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16</td>\n      <td>04.04.2013</td>\n      <td>0.110</td>\n      <td>153.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 2.6. Internally process the file in chunks (low_memory)<a class=\"anchor\" id=\"2.6\"></a>\nInternally process the file in chunks, resulting in lower memory use while parsing, but possibly mixed type inference. To ensure no mixed types specify the type with the dtype parameter."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/nlp-reports-news-classification/water_problem_nlp_ua_for_Kaggle_100.csv', delimiter=';', \n                 header=0, encoding='cp1251', low_memory=True,\n                 dtype = {'text': str, \n                          'env_problems': 'Int64',\n                          'pollution': 'Int64', \n                          'treatment': 'Int64',\n                          'climate': 'Int64',\n                          'biomonitoring': 'Int64'})\ndf.head(3)","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"                                                text  env_problems  pollution  \\\n0  У поверхневі води басейну Південного Бугу скид...             1          1   \n1  Згідно з державною статистичною звітністю (фор...             1          1   \n2  Показники об’ємів стічних вод серед різних гал...             1          1   \n\n   treatment  climate  biomonitoring  \n0       <NA>     <NA>           <NA>  \n1       <NA>     <NA>           <NA>  \n2       <NA>     <NA>           <NA>  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>env_problems</th>\n      <th>pollution</th>\n      <th>treatment</th>\n      <th>climate</th>\n      <th>biomonitoring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>У поверхневі води басейну Південного Бугу скид...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Згідно з державною статистичною звітністю (фор...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Показники об’ємів стічних вод серед різних гал...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 2.7. Download json-data via API in Kaggle<a class=\"anchor\" id=\"2.7\"></a>"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Download one file\nimport requests\nprint('Download daily data from the Portal of RNBO of Ukraine')\nmyfile = requests.get('https://api-covid19.rnbo.gov.ua/charts/main-data?mode=ukraine&fbclid=IwAR1vNXEE0nkmorUmGP4StG4cLrj1Z9VoX3c3Bi8dfltr0elgOj4b0M3ONvk')\nopen('filename', 'wb').write(myfile.content)\ndata_covid = pd.read_json('filename')\ndata_covid[:3]","execution_count":22,"outputs":[{"output_type":"stream","text":"Download daily data from the Portal of RNBO of Ukraine\n","name":"stdout"},{"output_type":"error","ename":"ConnectionError","evalue":"HTTPSConnectionPool(host='api-covid19.rnbo.gov.ua', port=443): Max retries exceeded with url: /charts/main-data?mode=ukraine&fbclid=IwAR1vNXEE0nkmorUmGP4StG4cLrj1Z9VoX3c3Bi8dfltr0elgOj4b0M3ONvk (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f97f6762690>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             )\n","\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f97f6762690>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    755\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api-covid19.rnbo.gov.ua', port=443): Max retries exceeded with url: /charts/main-data?mode=ukraine&fbclid=IwAR1vNXEE0nkmorUmGP4StG4cLrj1Z9VoX3c3Bi8dfltr0elgOj4b0M3ONvk (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f97f6762690>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-72e78ece08fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Download daily data from the Portal of RNBO of Ukraine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmyfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://api-covid19.rnbo.gov.ua/charts/main-data?mode=ukraine&fbclid=IwAR1vNXEE0nkmorUmGP4StG4cLrj1Z9VoX3c3Bi8dfltr0elgOj4b0M3ONvk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata_covid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api-covid19.rnbo.gov.ua', port=443): Max retries exceeded with url: /charts/main-data?mode=ukraine&fbclid=IwAR1vNXEE0nkmorUmGP4StG4cLrj1Z9VoX3c3Bi8dfltr0elgOj4b0M3ONvk (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f97f6762690>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))"]}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Download some files\nprint('Download daily data from the Portal of RNBO of Ukraine')\nfor filename in ['main-data?mode=ukraine&fbclid=IwAR1vNXEE0nkmorUmGP4StG4cLrj1Z9VoX3c3Bi8dfltr0elgOj4b0M3ONvk']:\n    url = f'https://api-covid19.rnbo.gov.ua/charts/{filename}'\n    myfile = requests.get(url)\n    open('filename.json', 'wb').write(myfile.content)\n    data_covid = pd.read_json('filename.json')\n    display(data_covid[:3])","execution_count":23,"outputs":[{"output_type":"stream","text":"Download daily data from the Portal of RNBO of Ukraine\n","name":"stdout"},{"output_type":"error","ename":"ConnectionError","evalue":"HTTPSConnectionPool(host='api-covid19.rnbo.gov.ua', port=443): Max retries exceeded with url: /charts/main-data?mode=ukraine&fbclid=IwAR1vNXEE0nkmorUmGP4StG4cLrj1Z9VoX3c3Bi8dfltr0elgOj4b0M3ONvk (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f97f64d3a10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             )\n","\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f97f64d3a10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    755\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api-covid19.rnbo.gov.ua', port=443): Max retries exceeded with url: /charts/main-data?mode=ukraine&fbclid=IwAR1vNXEE0nkmorUmGP4StG4cLrj1Z9VoX3c3Bi8dfltr0elgOj4b0M3ONvk (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f97f64d3a10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-a844a679deda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'main-data?mode=ukraine&fbclid=IwAR1vNXEE0nkmorUmGP4StG4cLrj1Z9VoX3c3Bi8dfltr0elgOj4b0M3ONvk'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'https://api-covid19.rnbo.gov.ua/charts/{filename}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmyfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filename.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata_covid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filename.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api-covid19.rnbo.gov.ua', port=443): Max retries exceeded with url: /charts/main-data?mode=ukraine&fbclid=IwAR1vNXEE0nkmorUmGP4StG4cLrj1Z9VoX3c3Bi8dfltr0elgOj4b0M3ONvk (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f97f64d3a10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))"]}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 2.8. Selection data from DataFrame (Pandas Tips)<a class=\"anchor\" id=\"2.8\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data_titanic.copy()\ndf.info()","execution_count":24,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In progress...\n# df.loc[], df.iloc, data.at\ndf.iloc[2:5, :].loc[:, \"Name\":\"Fare\"]","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"                                           Name     Sex   Age  SibSp  Parch  \\\n2                        Heikkinen, Miss. Laina  female  26.0      0      0   \n3  Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0   \n4                      Allen, Mr. William Henry    male  35.0      0      0   \n\n             Ticket    Fare  \n2  STON/O2. 3101282   7.925  \n3            113803  53.100  \n4            373450   8.050  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.925</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.050</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select multiple slices of columns from a df\ncols_str = list(map(str, list(df.columns))) # so that we can do df[\"0\"] as string for the example\ndf.columns = cols_str\n\n# Using pandas concatenation\n# if you are ever confused about axis = 1 or axis = 0, just put axis = \"columns\" or axis = \"rows\"\ndisplay(pd.concat([df.loc[:, \"PassengerId\":\"Pclass\"], df.loc[:, \"Sex\":\"SibSp\"]], axis = \"columns\").head(3))\n\n# Using lists\n# please ntoe that df.columns is a series with index, so we are using index to filter #\ndisplay(df[list(df.columns[0:3]) + list(df.columns[4:7])].head(3))\n\n# Using numpy\ndisplay(df.iloc[:, np.r_[0:3, 4:7]].head(3)) # probably the most beautiful solution","execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"   PassengerId  Survived  Pclass     Sex   Age  SibSp\n0            1         0       3    male  22.0      1\n1            2         1       1  female  38.0      1\n2            3         1       3  female  26.0      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   PassengerId  Survived  Pclass     Sex   Age  SibSp\n0            1         0       3    male  22.0      1\n1            2         1       1  female  38.0      1\n2            3         1       3  female  26.0      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   PassengerId  Survived  Pclass     Sex   Age  SibSp\n0            1         0       3    male  22.0      1\n1            2         1       1  female  38.0      1\n2            3         1       3  female  26.0      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)"},{"metadata":{},"cell_type":"markdown","source":"## 3. Auxiliary functions<a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"### Tip 3.1. Pandas option for output data<a class=\"anchor\" id=\"3.1\"></a>"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Sets the value of the specified option.\npd.set_option('max_columns',100)\npd.set_option('max_rows',20)","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Available options:\n> display.[chop_threshold, colheader_justify, column_space, date_dayfirst,\n>          date_yearfirst, encoding, expand_frame_repr, float_format, height,\n>          line_width, max_columns, max_colwidth, max_info_columns, max_info_rows,\n>          max_rows, max_seq_items, mpl_style, multi_sparse, notebook_repr_html,\n>          pprint_nest_depth, precision, width]"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_nlp.head(1)","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"                                                text  env_problems  pollution  \\\n0  У поверхневі води басейну Південного Бугу скид...           1.0        1.0   \n\n   treatment  climate  biomonitoring  \n0        NaN      NaN            NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>env_problems</th>\n      <th>pollution</th>\n      <th>treatment</th>\n      <th>climate</th>\n      <th>biomonitoring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>У поверхневі води басейну Південного Бугу скид...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('max_colwidth',200)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_nlp.head(1)","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"                                                                                                                                                         text  \\\n0  У поверхневі води басейну Південного Бугу скиди стічних вод надходять із 341 точкового джерела (дані інвентаризації джерел скидів проведеної у 2011 році).   \n\n   env_problems  pollution  treatment  climate  biomonitoring  \n0           1.0        1.0        NaN      NaN            NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>env_problems</th>\n      <th>pollution</th>\n      <th>treatment</th>\n      <th>climate</th>\n      <th>biomonitoring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>У поверхневі води басейну Південного Бугу скиди стічних вод надходять із 341 точкового джерела (дані інвентаризації джерел скидів проведеної у 2011 році).</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reset all of them options to default\npd.reset_option('all')","execution_count":31,"outputs":[{"output_type":"stream","text":"As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead.\n\n: boolean\n    use_inf_as_null had been deprecated and will be removed in a future\n    version. Use `use_inf_as_na` instead.\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 3.2. The garbage collector<a class=\"anchor\" id=\"3.2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"20"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)"},{"metadata":{"papermill":{"duration":0.029974,"end_time":"2020-11-15T02:05:20.229181","exception":false,"start_time":"2020-11-15T02:05:20.199207","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 4. EDA & Data cleaning<a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"### Tip 4.1. Count of rows that match a condition <a class=\"anchor\" id=\"4.1\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data_titanic.copy()\ndf.head()\ndf.shape\n\n# absolute values\n(df[\"Age\"] < 18).sum()\nprint(\"In the columns Age we have {} of rows that are below 18\".format((df[\"Age\"] < 18).sum()))\n\n# mean value\n(df[\"Age\"] < 18).mean()\nprint(\"In the columns Age the values that are below 18 represent {}%\".format((df[\"Age\"] < 18).mean()))","execution_count":33,"outputs":[{"output_type":"stream","text":"In the columns Age we have 113 of rows that are below 18\nIn the columns Age the values that are below 18 represent 0.12682379349046016%\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 4.2. Combine the small categories into a single category named \"Other\" <a class=\"anchor\" id=\"4.2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"class\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"E\", \"F\"]}\ndf = pd.DataFrame(d)\ndf\n\n# Step 1: count the frequencies\nfrequencies = df[\"class\"].value_counts(normalize = True)\nprint(frequencies)\n\n# Step 2: establish your threshold and filter the smaller categories\nthreshold = 0.1\nsmall_categories = frequencies[frequencies < threshold].index\nprint(small_categories)\n\n# Step 3: replace the values\ndf[\"class\"] = df[\"class\"].replace(small_categories, \"Other\")\ndf[\"class\"].value_counts(normalize = True)","execution_count":34,"outputs":[{"output_type":"stream","text":"A    0.454545\nB    0.181818\nD    0.090909\nF    0.090909\nE    0.090909\nC    0.090909\nName: class, dtype: float64\nIndex(['D', 'F', 'E', 'C'], dtype='object')\n","name":"stdout"},{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"A        0.454545\nOther    0.363636\nB        0.181818\nName: class, dtype: float64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 4.3. Count the missing values <a class=\"anchor\" id=\"4.3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"\"\\n\" in \"print\" - line skip in the text output "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data_titanic.copy()\n# Solution 1\nprint('df.isnull().sum().sum()')\nprint(df.isnull().sum().sum(), \"\\n\\n\")\n\n# Solution 2\nprint('df.isna().sum()\\n')\nprint(df.isna().sum(), \"\\n\\n\")\n\n# Solution 3\nprint('df.isna().any()\\n')\nprint(df.isna().any(), \"\\n\\n\")\n\n# Solution 4:\ndf.isna().any(axis = None)","execution_count":35,"outputs":[{"output_type":"stream","text":"df.isnull().sum().sum()\n866 \n\n\ndf.isna().sum()\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64 \n\n\ndf.isna().any()\n\nPassengerId    False\nSurvived       False\nPclass         False\nName           False\nSex            False\nAge             True\nSibSp          False\nParch          False\nTicket         False\nFare           False\nCabin           True\nEmbarked        True\ndtype: bool \n\n\n","name":"stdout"},{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 4.4. Convert one type of values to others <a class=\"anchor\" id=\"4.4\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do some fast feature eng on the DF\nd = {\"gender\":[\"male\", \"female\", \"male\"], \"color\":[\"red\", \"green\", \"blue\"], \"age\":[25, 30, 15]}\ndf = pd.DataFrame(d)\ndf\n\n# Solution\ndf[\"gender_mapped\"] = df[\"gender\"].map({\"male\":\"M\", \"female\":\"F\"}) # using dictionaries to map values\ndf[\"color_factorized\"] = df[\"color\"].factorize()[0] # using factorize: returns a tuple of arrays (array([0, 1, 2]), Index(['red', 'green', 'blue'], dtype='object')) that's why we select [0]\ndf[\"age_compared_boolean\"] = df[\"age\"] < 18 # return a True False boolean value\ndf[\"age_str\"] = df[\"age\"].astype('str')\n\ndf","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"   gender  color  age gender_mapped  color_factorized  age_compared_boolean  \\\n0    male    red   25             M                 0                 False   \n1  female  green   30             F                 1                 False   \n2    male   blue   15             M                 2                  True   \n\n  age_str  \n0      25  \n1      30  \n2      15  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>color</th>\n      <th>age</th>\n      <th>gender_mapped</th>\n      <th>color_factorized</th>\n      <th>age_compared_boolean</th>\n      <th>age_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>male</td>\n      <td>red</td>\n      <td>25</td>\n      <td>M</td>\n      <td>0</td>\n      <td>False</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>green</td>\n      <td>30</td>\n      <td>F</td>\n      <td>1</td>\n      <td>False</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>male</td>\n      <td>blue</td>\n      <td>15</td>\n      <td>M</td>\n      <td>2</td>\n      <td>True</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_titanic_num = data_titanic[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Embarked']].copy()\ndata_titanic_num[\"Sex\"] = data_titanic_num[\"Sex\"].map({\"female\":0, \"male\":1})\ndata_titanic_num[\"Embarked\"] = data_titanic_num[\"Embarked\"].map({\"S\":0, \"C\":1, \"Q\": 2})\ndata_titanic_num = data_titanic_num.dropna()  # without NAN \ndata_titanic_num","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"     Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n0           0       3    1  22.0      1      0   7.2500       0.0\n1           1       1    0  38.0      1      0  71.2833       1.0\n2           1       3    0  26.0      0      0   7.9250       0.0\n3           1       1    0  35.0      1      0  53.1000       0.0\n4           0       3    1  35.0      0      0   8.0500       0.0\n..        ...     ...  ...   ...    ...    ...      ...       ...\n885         0       3    0  39.0      0      5  29.1250       2.0\n886         0       2    1  27.0      0      0  13.0000       0.0\n887         1       1    0  19.0      0      0  30.0000       0.0\n889         1       1    1  26.0      0      0  30.0000       1.0\n890         0       3    1  32.0      0      0   7.7500       2.0\n\n[712 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>885</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>29.1250</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>712 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 4.5. Replaced inf, -inf, nan to given value <a class=\"anchor\" id=\"4.5\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_titanic['Age'].replace([np.inf, -np.inf], np.nan).fillna(0)","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"0      22.0\n1      38.0\n2      26.0\n3      35.0\n4      35.0\n       ... \n886    27.0\n887    19.0\n888     0.0\n889    26.0\n890    32.0\nName: Age, Length: 891, dtype: float64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 4.6. Filtering the missing data in DataFrame<a class=\"anchor\" id=\"4.6\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_titanic.shape","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"(891, 12)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_titanic.dropna().reset_index(drop=True)","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"     PassengerId  Survived  Pclass  \\\n0              2         1       1   \n1              4         1       1   \n2              7         0       1   \n3             11         1       3   \n4             12         1       1   \n..           ...       ...     ...   \n178          872         1       1   \n179          873         0       1   \n180          880         1       1   \n181          888         1       1   \n182          890         1       1   \n\n                                                  Name     Sex   Age  SibSp  \\\n0    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n1         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n2                              McCarthy, Mr. Timothy J    male  54.0      0   \n3                      Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n4                             Bonnell, Miss. Elizabeth  female  58.0      0   \n..                                                 ...     ...   ...    ...   \n178   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n179                           Carlsson, Mr. Frans Olof    male  33.0      0   \n180      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n181                       Graham, Miss. Margaret Edith  female  19.0      0   \n182                              Behr, Mr. Karl Howell    male  26.0      0   \n\n     Parch    Ticket     Fare        Cabin Embarked  \n0        0  PC 17599  71.2833          C85        C  \n1        0    113803  53.1000         C123        S  \n2        0     17463  51.8625          E46        S  \n3        1   PP 9549  16.7000           G6        S  \n4        0    113783  26.5500         C103        S  \n..     ...       ...      ...          ...      ...  \n178      1     11751  52.5542          D35        S  \n179      0       695   5.0000  B51 B53 B55        S  \n180      1     11767  83.1583          C50        C  \n181      0    112053  30.0000          B42        S  \n182      0    111369  30.0000         C148        C  \n\n[183 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>McCarthy, Mr. Timothy J</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Sandstrom, Miss. Marguerite Rut</td>\n      <td>female</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>PP 9549</td>\n      <td>16.7000</td>\n      <td>G6</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Bonnell, Miss. Elizabeth</td>\n      <td>female</td>\n      <td>58.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113783</td>\n      <td>26.5500</td>\n      <td>C103</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>872</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>11751</td>\n      <td>52.5542</td>\n      <td>D35</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>873</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Carlsson, Mr. Frans Olof</td>\n      <td>male</td>\n      <td>33.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>695</td>\n      <td>5.0000</td>\n      <td>B51 B53 B55</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>880</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n      <td>female</td>\n      <td>56.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>11767</td>\n      <td>83.1583</td>\n      <td>C50</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>183 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T02:05:20.381043Z","iopub.status.busy":"2020-11-15T02:05:20.380193Z","iopub.status.idle":"2020-11-15T02:05:20.385349Z","shell.execute_reply":"2020-11-15T02:05:20.384773Z"},"papermill":{"duration":0.054558,"end_time":"2020-11-15T02:05:20.385518","exception":false,"start_time":"2020-11-15T02:05:20.33096","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_titanic[['Name', 'Age']].dropna().reset_index(drop=True)","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"                                                  Name   Age\n0                              Braund, Mr. Owen Harris  22.0\n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0\n2                               Heikkinen, Miss. Laina  26.0\n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0\n4                             Allen, Mr. William Henry  35.0\n..                                                 ...   ...\n709               Rice, Mrs. William (Margaret Norton)  39.0\n710                              Montvila, Rev. Juozas  27.0\n711                       Graham, Miss. Margaret Edith  19.0\n712                              Behr, Mr. Karl Howell  26.0\n713                                Dooley, Mr. Patrick  32.0\n\n[714 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>38.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Allen, Mr. William Henry</td>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>709</th>\n      <td>Rice, Mrs. William (Margaret Norton)</td>\n      <td>39.0</td>\n    </tr>\n    <tr>\n      <th>710</th>\n      <td>Montvila, Rev. Juozas</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>711</th>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>712</th>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>713</th>\n      <td>Dooley, Mr. Patrick</td>\n      <td>32.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>714 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 4.7. Generate descriptive statistics<a class=\"anchor\" id=\"4.7\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_health.describe()","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"              age         sex          cp    trestbps        chol         fbs  \\\ncount  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \nmean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \nstd      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \nmin     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \nmax     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n\n          restecg     thalach       exang     oldpeak       slope          ca  \\\ncount  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \nmean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \nstd      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \nmin      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \nmax      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n\n             thal      target  \ncount  303.000000  303.000000  \nmean     2.313531    0.544554  \nstd      0.612277    0.498835  \nmin      0.000000    0.000000  \n25%      2.000000    0.000000  \n50%      2.000000    1.000000  \n75%      3.000000    1.000000  \nmax      3.000000    1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>54.366337</td>\n      <td>0.683168</td>\n      <td>0.966997</td>\n      <td>131.623762</td>\n      <td>246.264026</td>\n      <td>0.148515</td>\n      <td>0.528053</td>\n      <td>149.646865</td>\n      <td>0.326733</td>\n      <td>1.039604</td>\n      <td>1.399340</td>\n      <td>0.729373</td>\n      <td>2.313531</td>\n      <td>0.544554</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.082101</td>\n      <td>0.466011</td>\n      <td>1.032052</td>\n      <td>17.538143</td>\n      <td>51.830751</td>\n      <td>0.356198</td>\n      <td>0.525860</td>\n      <td>22.905161</td>\n      <td>0.469794</td>\n      <td>1.161075</td>\n      <td>0.616226</td>\n      <td>1.022606</td>\n      <td>0.612277</td>\n      <td>0.498835</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>29.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>94.000000</td>\n      <td>126.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>71.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>47.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>120.000000</td>\n      <td>211.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>133.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>55.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>130.000000</td>\n      <td>240.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>153.000000</td>\n      <td>0.000000</td>\n      <td>0.800000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>61.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>140.000000</td>\n      <td>274.500000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>166.000000</td>\n      <td>1.000000</td>\n      <td>1.600000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>77.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>200.000000</td>\n      <td>564.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>202.000000</td>\n      <td>1.000000</td>\n      <td>6.200000</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)"},{"metadata":{"papermill":{"duration":0.036817,"end_time":"2020-11-15T02:05:21.573582","exception":false,"start_time":"2020-11-15T02:05:21.536765","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 5. FE<a class=\"anchor\" id=\"5\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"### Tip 5.1. Search and encoding categorical columns <a class=\"anchor\" id=\"5.1\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_titanic.head(3)","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ndef df_encoding(df):\n    numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    categorical_columns = []\n    features = df.columns.values.tolist()\n    for col in features:\n        if df[col].dtype in numerics: continue\n        categorical_columns.append(col)\n    print('Categorical columns:', categorical_columns)\n\n    for col in categorical_columns:\n        if col in df.columns:\n            le = LabelEncoder()\n            le.fit(list(df[col].astype(str).values))\n            df[col] = le.transform(list(df[col].astype(str).values))\n    \n    return df","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_encoding(data_titanic)","execution_count":45,"outputs":[{"output_type":"stream","text":"Categorical columns: ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n","name":"stdout"},{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"     PassengerId  Survived  Pclass  Name  Sex   Age  SibSp  Parch  Ticket  \\\n0              1         0       3   108    1  22.0      1      0     523   \n1              2         1       1   190    0  38.0      1      0     596   \n2              3         1       3   353    0  26.0      0      0     669   \n3              4         1       1   272    0  35.0      1      0      49   \n4              5         0       3    15    1  35.0      0      0     472   \n..           ...       ...     ...   ...  ...   ...    ...    ...     ...   \n886          887         0       2   548    1  27.0      0      0     101   \n887          888         1       1   303    0  19.0      0      0      14   \n888          889         0       3   413    0   NaN      1      2     675   \n889          890         1       1    81    1  26.0      0      0       8   \n890          891         0       3   220    1  32.0      0      0     466   \n\n        Fare  Cabin  Embarked  \n0     7.2500    147         2  \n1    71.2833     81         0  \n2     7.9250    147         2  \n3    53.1000     55         2  \n4     8.0500    147         2  \n..       ...    ...       ...  \n886  13.0000    147         2  \n887  30.0000     30         2  \n888  23.4500    147         2  \n889  30.0000     60         0  \n890   7.7500    147         1  \n\n[891 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>108</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>523</td>\n      <td>7.2500</td>\n      <td>147</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>190</td>\n      <td>0</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>596</td>\n      <td>71.2833</td>\n      <td>81</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>353</td>\n      <td>0</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>669</td>\n      <td>7.9250</td>\n      <td>147</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>272</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>49</td>\n      <td>53.1000</td>\n      <td>55</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>15</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>472</td>\n      <td>8.0500</td>\n      <td>147</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>548</td>\n      <td>1</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>101</td>\n      <td>13.0000</td>\n      <td>147</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>303</td>\n      <td>0</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>30.0000</td>\n      <td>30</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>413</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>675</td>\n      <td>23.4500</td>\n      <td>147</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>81</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>30.0000</td>\n      <td>60</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>220</td>\n      <td>1</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>466</td>\n      <td>7.7500</td>\n      <td>147</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tip 5.2. Difference and rolling of values in DataFrame<a class=\"anchor\" id=\"5.2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_covid['confirmed'].plot()","execution_count":46,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'data_covid' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-0db96da51382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_covid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'confirmed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'data_covid' is not defined"]}]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T02:05:20.297258Z","iopub.status.busy":"2020-11-15T02:05:20.296364Z","iopub.status.idle":"2020-11-15T02:05:20.300125Z","shell.execute_reply":"2020-11-15T02:05:20.299384Z"},"papermill":{"duration":0.041056,"end_time":"2020-11-15T02:05:20.300251","exception":false,"start_time":"2020-11-15T02:05:20.259195","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Daily gain\ndata_covid['n_confirmed'] = data_covid['confirmed'].diff()\ndata_covid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_covid['n_confirmed'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sliding total for a week\ndata_covid['n_confirmed_week'] = data_covid['n_confirmed'].rolling(7).sum()\ndata_covid['n_confirmed_week']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_covid['n_confirmed_week'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot with all these features\n(data_covid['confirmed']/data_covid['confirmed'].max()).plot()\n(data_covid['n_confirmed']/data_covid['n_confirmed'].max()).plot()\n(data_covid['n_confirmed_week']/data_covid['n_confirmed_week'].max()).plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 5.3. Data dropping (rows or columns removing) in DataFrame<a class=\"anchor\" id=\"5.3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_titanic.drop(columns = ['Ticket', 'Cabin'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dublicates removing\nprint(data_health.shape)\ndisplay(data_health.drop_duplicates())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 5.4. Date in str format to date in datetime format in DataFrame<a class=\"anchor\" id=\"5.4\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_covid['date'] = pd.to_datetime(data_covid['dates'])\n# Forced conversion\npd.to_datetime(data_covid[\"dates\"], format = '%Y-%m-%d', errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 5.5. MinMaxScaling data in DataFrame<a class=\"anchor\" id=\"5.5\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef df_minmax_scaler(df):\n    # Data Scalling\n    scaler = MinMaxScaler().fit(df)\n    df = pd.DataFrame(scaler.transform(df), columns = df.columns)\n    return scaler, df","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler, df = df_minmax_scaler(data_health.copy())\ndf","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"          age  sex        cp  trestbps      chol  fbs  restecg   thalach  \\\n0    0.708333  1.0  1.000000  0.481132  0.244292  1.0      0.0  0.603053   \n1    0.166667  1.0  0.666667  0.339623  0.283105  0.0      0.5  0.885496   \n2    0.250000  0.0  0.333333  0.339623  0.178082  0.0      0.0  0.770992   \n3    0.562500  1.0  0.333333  0.245283  0.251142  0.0      0.5  0.816794   \n4    0.583333  0.0  0.000000  0.245283  0.520548  0.0      0.5  0.702290   \n..        ...  ...       ...       ...       ...  ...      ...       ...   \n298  0.583333  0.0  0.000000  0.433962  0.262557  0.0      0.5  0.396947   \n299  0.333333  1.0  1.000000  0.150943  0.315068  0.0      0.5  0.465649   \n300  0.812500  1.0  0.000000  0.471698  0.152968  1.0      0.5  0.534351   \n301  0.583333  1.0  0.000000  0.339623  0.011416  0.0      0.5  0.335878   \n302  0.583333  0.0  0.333333  0.339623  0.251142  0.0      0.0  0.786260   \n\n     exang   oldpeak  slope    ca      thal  target  \n0      0.0  0.370968    0.0  0.00  0.333333     1.0  \n1      0.0  0.564516    0.0  0.00  0.666667     1.0  \n2      0.0  0.225806    1.0  0.00  0.666667     1.0  \n3      0.0  0.129032    1.0  0.00  0.666667     1.0  \n4      1.0  0.096774    1.0  0.00  0.666667     1.0  \n..     ...       ...    ...   ...       ...     ...  \n298    1.0  0.032258    0.5  0.00  1.000000     0.0  \n299    0.0  0.193548    0.5  0.00  1.000000     0.0  \n300    0.0  0.548387    0.5  0.50  1.000000     0.0  \n301    1.0  0.193548    0.5  0.25  1.000000     0.0  \n302    0.0  0.000000    0.5  0.25  0.666667     0.0  \n\n[303 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.708333</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.481132</td>\n      <td>0.244292</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.603053</td>\n      <td>0.0</td>\n      <td>0.370968</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.166667</td>\n      <td>1.0</td>\n      <td>0.666667</td>\n      <td>0.339623</td>\n      <td>0.283105</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.885496</td>\n      <td>0.0</td>\n      <td>0.564516</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.666667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.250000</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.339623</td>\n      <td>0.178082</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.770992</td>\n      <td>0.0</td>\n      <td>0.225806</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.666667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.562500</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.245283</td>\n      <td>0.251142</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.816794</td>\n      <td>0.0</td>\n      <td>0.129032</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.666667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.583333</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.245283</td>\n      <td>0.520548</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.702290</td>\n      <td>1.0</td>\n      <td>0.096774</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.666667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>0.583333</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.433962</td>\n      <td>0.262557</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.396947</td>\n      <td>1.0</td>\n      <td>0.032258</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.150943</td>\n      <td>0.315068</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.465649</td>\n      <td>0.0</td>\n      <td>0.193548</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>0.812500</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.471698</td>\n      <td>0.152968</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.534351</td>\n      <td>0.0</td>\n      <td>0.548387</td>\n      <td>0.5</td>\n      <td>0.50</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>0.583333</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.339623</td>\n      <td>0.011416</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.335878</td>\n      <td>1.0</td>\n      <td>0.193548</td>\n      <td>0.5</td>\n      <td>0.25</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>0.583333</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.339623</td>\n      <td>0.251142</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.786260</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.5</td>\n      <td>0.25</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)"},{"metadata":{"papermill":{"duration":0.038107,"end_time":"2020-11-15T02:05:24.595869","exception":false,"start_time":"2020-11-15T02:05:24.557762","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 6. Modeling<a class=\"anchor\" id=\"6\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"Thanks to [Heart Disease - Automatic AdvEDA & FE & 20 models](https://www.kaggle.com/vbmokin/heart-disease-automatic-adveda-fe-20-models)\n\nThere are 60+ predictive modeling algorithms to choose from. Consider the classification problem with the next models (with hyperparameters tuning by GridSearchCV):\n\n- Linear Regression, Logistic Regression\n- Naive Bayes \n- k-Nearest Neighbors algorithm\n- Neural network with Keras\n- Support Vector Machines and Linear SVC\n- Stochastic Gradient Descent, Gradient Boosting Classifier, RidgeCV, Bagging Classifier\n- Decision Tree Classifier, Random Forest Classifier, AdaBoost Classifier, XGB Classifier, LGBM Classifier, ExtraTrees Classifier \n- Gaussian Process Classification\n- MLP Classifier (Deep Learning)\n- Voting Classifier\n\nApplication and tuning of these models using cross-validation with [learning_curve](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html?highlight=learning_curve#sklearn.model_selection.learning_curve) see in the notebook [Heart Disease - Automatic AdvEDA & FE & 20 models](https://www.kaggle.com/vbmokin/heart-disease-automatic-adveda-fe-20-models)."},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.1. Data preparation with standardization for modeling<a class=\"anchor\" id=\"6.1\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_health.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data preparation for data_health (very simple)\ndata_h = data_health.copy()\ntarget_data_h = data_h.pop('target')\ndisplay(data_h.head(3))\ndata_h.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data preparation for data_titanic (real - classification task)\nfrom sklearn.preprocessing import StandardScaler\n\ndata = data_titanic.copy()\ndata.index = data['PassengerId']  # it's need removed all id-features with unique values\ndata = data.drop(columns=['PassengerId'])\ndata = data.dropna()  # it's very simple but not good approach\ntarget_data = data.pop('Survived')\nscaler = StandardScaler()\ndata = pd.DataFrame(scaler.fit_transform(data), columns = data.columns)\ndisplay(data.head(3))\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_water.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data preparation for data_water (real - regression task)\ndata_w = data_water.copy()\ndata_w = data_w.drop(columns=['date'])\ntarget_data_w = data_w.pop('target')\nscaler_w = StandardScaler()\ndata_w = pd.DataFrame(scaler_w.fit_transform(data_w), columns = data_w.columns)\ndisplay(data_w.head(3))\ndata_w.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.2. Splitting data with train_test_split<a class=\"anchor\" id=\"6.2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# For data_health\ntrain, test, target, target_test = train_test_split(data, target_data, test_size=0.2, random_state=0)\nprint(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For data_water\ntrain_w, test_w, target_w, target_test_w = train_test_split(data_w, target_data_w, test_size=0.2, random_state=0)\nprint(train_w.shape, test_w.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.3. Accuracy score for train and test prediction<a class=\"anchor\" id=\"6.3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score, accuracy_score\n\ndef acc(model, train, test, target, target_test, is_round=True):\n    # Calculation accuracy score for train and test prediction\n    # is_round=True - for classification task only, for regression task is_round=False\n    \n    if is_round:\n        # Classification task\n        ytrain = model.predict(train).astype(int)\n        ytest = model.predict(test).astype(int)\n        acc_train = round(accuracy_score(target, ytrain), 2)\n        acc_test = round(accuracy_score(target_test, ytest), 2)\n    else:\n        # Regression task\n        ytrain = model.predict(train)\n        ytest = model.predict(test)\n        acc_train = round(r2_score(target, ytrain), 2)\n        acc_test = round(r2_score(target_test, ytest), 2)\n        \n    print('Accuracy for train prediction =', acc_train)\n    print('Accuracy for test prediction =', acc_test,'\\n')\n    \n    return ytrain, ytest\n\n# See examples below","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.4. Classification report<a class=\"anchor\" id=\"6.4\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\ndef classification_report_print(y_true, y_pred, title, target_names=['0', '1']):\n    print(f'Classification report {title}:')\n    print(classification_report(y_true, y_pred, target_names=target_names))\n\n# See examples below","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.5. Linear Regression <a class=\"anchor\" id=\"6.5\"></a>"},{"metadata":{},"cell_type":"markdown","source":"**Linear Regression** is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression. Reference [Wikipedia](https://en.wikipedia.org/wiki/Linear_regression).\n\nNote the confidence score generated by the model based on our training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Regression\nfrom sklearn.linear_model import LinearRegression\nlinreg = LinearRegression()\nlinreg.fit(train, target)\n\nytrain, ytest = acc(linreg, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.6. Support Vector Machines <a class=\"anchor\" id=\"6.6\"></a>"},{"metadata":{},"cell_type":"markdown","source":"**Support Vector Machines** are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training samples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new test samples to one category or the other, making it a non-probabilistic binary linear classifier. Reference [Wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine)."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Support Vector Machines\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\nsvr = SVC()\nsvr_CV = GridSearchCV(svr, param_grid={'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n                                       'tol': [1e-3]}, verbose=False)\nsvr_CV.fit(train, target)\nprint(svr_CV.best_params_,'\\n')\n\nytrain, ytest = acc(svr_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.7. Linear SVC <a class=\"anchor\" id=\"6.7\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear SVR\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import GridSearchCV\n\nlinear_svc = LinearSVC()\nparam_grid = {'dual':[False],\n              'C': np.linspace(1, 15, 15)}\nlinear_svc_CV = GridSearchCV(linear_svc, param_grid=param_grid, verbose=False)\nlinear_svc_CV.fit(train, target)\nprint(linear_svc_CV.best_params_,'\\n')\n\nytrain, ytest = acc(linear_svc_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.8. Decision Tree Classifier & Regressor<a class=\"anchor\" id=\"6.8\"></a>"},{"metadata":{},"cell_type":"markdown","source":"This model uses a **Decision Tree** as a predictive model which maps features (tree branches) to conclusions about the target value (tree leaves). Tree models where the target variable can take a finite set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree Classifier for data_health\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ndecision_tree = DecisionTreeClassifier()\nparam_grid = {'min_samples_leaf': [i for i in range(2,10)]}\ndecision_tree_CV = GridSearchCV(decision_tree, param_grid=param_grid, verbose=False)\ndecision_tree_CV.fit(train, target)\nprint(decision_tree_CV.best_params_, '\\n')\n\nytrain, ytest = acc(decision_tree_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DecisionTreeRegressor for data_water\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# Parameters of model (param_grid) taken from the notebook https://www.kaggle.com/vbmokin/ai-ml-ds-training-l2t-nh4-tree-regress-models\ndecision_tree = DecisionTreeRegressor()\nparam_grid = {'min_samples_leaf': [i for i in range(2,10)]}\ndecision_tree_CV_w = GridSearchCV(decision_tree, param_grid=param_grid, verbose=False)\ndecision_tree_CV_w.fit(train_w, target_w)\nprint(decision_tree_CV_w.best_params_, '\\n')\n\nytrain_dt_w, ytest_dt_w = acc(decision_tree_CV_w, train_w, test_w, target_w, target_test_w, is_round=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.9. Random Forest Classifier & Regressor <a class=\"anchor\" id=\"6.9\"></a>"},{"metadata":{},"cell_type":"markdown","source":"**Random Forest** is one of the most popular model. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators= [100, 300]) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Random_forest)."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Random Forest for data_health\n# Parameters of model (param_grid) taken from the notebook https://www.kaggle.com/morenovanton/titanic-random-forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nrandom_forest = RandomForestClassifier()\nparam_grid = {'n_estimators': [40, 50, 60], 'min_samples_split': [40, 50, 60, 70], 'min_samples_leaf': [12, 13, 14, 15, 16, 17], \n              'max_features': ['auto'], 'max_depth': [3, 4, 5, 6], 'criterion': ['gini'], 'bootstrap': [False]}\nrandom_forest_CV = GridSearchCV(estimator=random_forest, param_grid=param_grid, verbose=False)\nrandom_forest_CV.fit(train, target)\nprint(random_forest_CV.best_params_, '\\n')\n\nytrain, ytest = acc(random_forest_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Random Forest for data_water\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# Parameters of model (param_grid) taken from the notebook https://www.kaggle.com/vbmokin/ai-ml-ds-training-l2t-nh4-tree-regress-models\nrandom_forest = RandomForestRegressor()\nparam_grid = {'n_estimators': [10, 100, 500], 'min_samples_leaf': [i for i in range(5,10)], \n              'max_features': ['auto'], 'max_depth': [i for i in range(4,6)], \n              'criterion': ['mse'], 'bootstrap': [False]}\nrandom_forest_CV_w = GridSearchCV(estimator=random_forest, param_grid=param_grid, verbose=False)\nrandom_forest_CV_w.fit(train_w, target_w)\nprint(random_forest_CV_w.best_params_, '\\n')\n\nytrain_rf_w, ytest_rf_w = acc(random_forest_CV_w, train_w, test_w, target_w, target_test_w, is_round=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.10. XGB Classifier <a class=\"anchor\" id=\"6.10\"></a>"},{"metadata":{},"cell_type":"markdown","source":"**XGBoost** is an ensemble tree method that apply the principle of boosting weak learners (CARTs generally) using the gradient descent architecture. XGBoost improves upon the base Gradient Boosting Machines (GBM) framework through systems optimization and algorithmic enhancements. Reference [Towards Data Science.](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# XGBoost Classifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nxgb_clf = xgb.XGBClassifier(objective='reg:logistic') \nparameters = {'n_estimators': [50, 60, 70, 80, 90], \n              'learning_rate': [0.09, 0.1, 0.15, 0.2],\n              'max_depth': [3, 4, 5]}\nxgb_reg = GridSearchCV(estimator=xgb_clf, param_grid=parameters).fit(train, target)\nprint(\"Best score: %0.3f\" % xgb_reg.best_score_)\nprint(\"Best parameters set:\", xgb_reg.best_params_, '\\n')\n\nytrain, ytest = acc(xgb_reg, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.11. LGBM Classifier <a class=\"anchor\" id=\"6.11\"></a>"},{"metadata":{},"cell_type":"markdown","source":"**Light GBM** is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithms. It splits the tree leaf wise with the best fit whereas other boosting algorithms split the tree depth wise or level wise rather than leaf-wise. So when growing on the same leaf in Light GBM, the leaf-wise algorithm can reduce more loss than the level-wise algorithm and hence results in much better accuracy which can rarely be achieved by any of the existing boosting algorithms. Also, it is surprisingly very fast, hence the word ‘Light’. Reference [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/)."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n#%% split training set to validation set\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.2, random_state=0)\nmodelL = lgb.LGBMClassifier(n_estimators=1000, num_leaves=40)\nmodelL.fit(Xtrain, Ztrain, eval_set=[(Xval, Zval)], early_stopping_rounds=50, verbose=True)\n\nytrain, ytest = acc(modelL, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.12. Logistic Regression <a class=\"anchor\" id=\"6.12\"></a>"},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression** is a useful model to run early in the workflow. Logistic regression measures the relationship between the categorical dependent variable (feature) and one or more independent variables (features) by estimating probabilities using a logistic function, which is the cumulative logistic distribution. Reference [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\nlogreg = LogisticRegression()\nlogreg_CV = GridSearchCV(estimator=logreg, param_grid={'C' : [.2, .3, .4]}, verbose=False)\nlogreg_CV.fit(train, target)\nprint(logreg_CV.best_params_, '\\n')\n\nytrain, ytest = acc(logreg_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.13. k-Nearest Neighbors (KNN) <a class=\"anchor\" id=\"6.13\"></a>"},{"metadata":{},"cell_type":"markdown","source":"In pattern recognition, the **k-Nearest Neighbors algorithm** (or k-NN for short) is a non-parametric method used for classification and regression. A sample is classified by a majority vote of its neighbors, with the sample being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). Reference [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN - k-Nearest Neighbors algorithm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nknn = KNeighborsClassifier()\nknn_CV = GridSearchCV(estimator=knn, param_grid={'n_neighbors': range(2, 7)}, \n                      verbose=False).fit(train, target)\nprint(knn_CV.best_params_, '\\n')\n\nytrain, ytest = acc(knn_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.14. MLP Classifier <a class=\"anchor\" id=\"6.14\"></a>"},{"metadata":{},"cell_type":"markdown","source":"The **MLPClassifier** optimizes the squared-loss using LBFGS or stochastic gradient descent by the Multi-layer Perceptron regressor. Reference [Sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor)."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# MLPClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nmlp = MLPClassifier()\nparam_grid = {'hidden_layer_sizes': [i for i in range(2,5)],\n              'solver': ['sgd'],\n              'learning_rate': ['adaptive'],\n              'max_iter': [1000]\n              }\nmlp_GS = GridSearchCV(mlp, param_grid=param_grid, verbose=False)\nmlp_GS.fit(train, target)\nprint(mlp_GS.best_params_, '\\n')\n\nytrain, ytest = acc(mlp_GS, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.15. Voting Classifier <a class=\"anchor\" id=\"6.15\"></a>"},{"metadata":{},"cell_type":"markdown","source":"There is **VotingClassifier**. The idea behind the VotingClassifier is to combine conceptually different machine learning classifiers and use a majority vote (hard vote) or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# See start at \"Tip 6.12. Logistic Regression\" (logreg_CV), \n# \"Tip 6.14. MLP Classifier\" (mlp_GS) and \"Tip 6.7. Linear SVC\" (linear_svc_CV)\n# Voting Classifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nVoting_ens = VotingClassifier(estimators=[('log', logreg_CV), ('mlp', mlp_GS ), ('svc', linear_svc_CV)])\nVoting_ens.fit(train, target)\n\nytrain, ytest = acc(Voting_ens, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 6.16. Feature importance diagram <a class=\"anchor\" id=\"6.16\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# See start at \"Tip 6.11. LGBM Classifier\"\n# Feature importance diagram\nfig =  plt.figure(figsize = (10,10))\naxes = fig.add_subplot(111)\nlgb.plot_importance(modelL,ax = axes,height = 0.5)\nplt.show();\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In progress..."},{"metadata":{},"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)"},{"metadata":{},"cell_type":"markdown","source":"## 7. Analysis and visualization of modeling results<a class=\"anchor\" id=\"7\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"### Tip 7.1. Output results<a class=\"anchor\" id=\"7.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### Tip 7.2. Drawing plot data with modeling results<a class=\"anchor\" id=\"7.2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_prediction(target, y_list, label_list, data_name, MAV=0.5):\n    # Thanks to https://www.kaggle.com/vbmokin/ai-ml-ds-training-l3at-nh4-nn-models\n    # Building plot with target, Maximum allowable value (MAV) and \n    # prediction for the data_name (training, validation or test) data by 3 models\n    \n    x = np.arange(len(y_list[0]))\n    plt.figure(figsize=(16,10))\n    if target is not None:\n        plt.scatter(x, target, label = \"Target data\")\n    for i in range(len(y_list)):\n        plt.scatter(x, y_list[i], label = label_list[i])\n    plt.plot(x, np.full(len(y_list[0]), MAV), label = \"Maximum allowable value\", color = 'r')\n    plt.title(f'Prediction for the {data_name} data')\n    plt.legend(loc='best')\n    plt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_name = ['Decision Tree prediction', 'Random Forest prediction']\nplot_prediction(target_w, [ytrain_dt_w, ytrain_rf_w], models_name, 'training', MAV=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tip 7.3. Drawing plot data of DataFrame (Pandas)<a class=\"anchor\" id=\"7.3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# In progress...\n#df.plot(kind = \"scatter\", x = \"spirit_servings\", y = \"wine_servings\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# In progress...\n# Interactive plots out of the box in pandas\n# run !pip install hvplot\n#pd.options.plotting.backend = \"hvplot\"\n#df.plot(kind = \"scatter\", x = \"spirit_servings\", y = \"wine_servings\", c = \"continent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)"},{"metadata":{},"cell_type":"markdown","source":"In progress..."},{"metadata":{},"cell_type":"markdown","source":"## 8. BONUS<a class=\"anchor\" id=\"8\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"### Tip 8.1. Submission data from DataFrame to Kaggle competition<a class=\"anchor\" id=\"8.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### Competition [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# From https://www.kaggle.com/vbmokin/titanic-top-score-one-line-of-the-prediction\ntraindf = pd.read_csv('../input/titanic/train.csv').set_index('PassengerId')\ntestdf = pd.read_csv('../input/titanic/test.csv').set_index('PassengerId')\ndf = pd.concat([traindf, testdf], axis=0, sort=False)\ndf['Title'] = df.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ndf['IsWomanOrBoy'] = ((df.Title == 'Master') | (df.Sex == 'female'))\ndf['LastName'] = df.Name.str.split(',').str[0]\nfamily = df.groupby(df.LastName).Survived\ndf['WomanOrBoyCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).count())\ndf['WomanOrBoyCount'] = df.mask(df.IsWomanOrBoy, df.WomanOrBoyCount - 1, axis=0)\ndf['FamilySurvivedCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).sum())\ndf['FamilySurvivedCount'] = df.mask(df.IsWomanOrBoy, df.FamilySurvivedCount - df.Survived.fillna(0), axis=0)\ndf['WomanOrBoySurvived'] = df.FamilySurvivedCount / df.WomanOrBoyCount.replace(0, np.nan)\ndf['Alone'] = (df.WomanOrBoyCount == 0)\ndf = pd.concat([df.WomanOrBoySurvived.fillna(0), df.Alone, df.Sex.replace({'male': 0, 'female': 1})], axis=1)\ntest_x = df.loc[testdf.index]\ntest_x['Survived'] = (((test_x.WomanOrBoySurvived <= 0.238) & (test_x.Sex > 0.5) & (test_x.Alone > 0.5)) | \\\n          ((test_x.WomanOrBoySurvived > 0.238) & \\\n           ~((test_x.WomanOrBoySurvived > 0.55) & (test_x.WomanOrBoySurvived <= 0.633))))\npd.DataFrame({'Survived': test_x['Survived'].astype(int)}, \\\n             index=testdf.index).reset_index().to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Result: the file \"submission.csv\" gives LB = 0.80382 (Top 4%)"},{"metadata":{"papermill":{"duration":0.043475,"end_time":"2020-11-15T02:05:28.535056","exception":false,"start_time":"2020-11-15T02:05:28.491581","status":"completed"},"tags":[]},"cell_type":"markdown","source":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\n[Go to Top](#0)"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}